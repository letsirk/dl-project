{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iWildCam 2019\n",
    "### Deep Learning Project\n",
    "\n",
    "This notebook is inspired by https://www.kaggle.com/xhlulu/cnn-baseline-iwildcam-2019, https://www.kaggle.com/xhlulu/reducing-image-sizes-to-32x32 and https://github.com/cfotache/pytorch_objectdetecttrack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0') if CUDA else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess data\n",
    "* Load the 32x32 dataset produced with https://www.kaggle.com/xhlulu/reducing-image-sizes-to-32x32\n",
    "* Change the dimension of the images from [32,32,3] to [3,32,32] (for Darknet model)\n",
    "* Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_array_dimension(images, labels, num_images, include_empty_images=True):\n",
    "    \"\"\"\n",
    "    Change dimension of images from [32,32,3] to [3,32,32]\n",
    "    \n",
    "    Args:\n",
    "    images                target images to be converted to different dimension\n",
    "    num_images            total number of images included to result\n",
    "    include_empty_images  if True, empty images are included to result\n",
    "    \"\"\"\n",
    "    images_temp = []\n",
    "    for i in range(0, num_images):\n",
    "        if include_empty_images or (len(labels)>=i and labels[i] != 0):\n",
    "            temp = []\n",
    "            temp.append(images[i][:,:,0]) \n",
    "            temp.append(images[i][:,:,1])\n",
    "            temp.append(images[i][:,:,2])\n",
    "            images_temp.append(temp)\n",
    "    images_temp = np.array(images_temp)\n",
    "    labels_temp = labels[:num_images] if len(labels)>=num_images else []\n",
    "    if include_empty_images==False: labels_temp = labels_temp[labels_temp != 0]\n",
    "        \n",
    "    return images_temp, labels_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading the 32x32 dataset ####\n",
    "if preprocess:\n",
    "    # The data, split between train and test sets:\n",
    "    x_train = np.load('./input/preprocess/reducing-image-sizes-to-32x32/X_train.npy')\n",
    "    x_test = np.load('./input/preprocess/reducing-image-sizes-to-32x32/X_test.npy')\n",
    "    y_train = np.load('./input/preprocess/reducing-image-sizes-to-32x32/y_train.npy')\n",
    "\n",
    "    # Convert the images to float and scale it to a range of 0 to 1\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255.\n",
    "    x_test /= 255.\n",
    "\n",
    "    #Convert y train binary values to numeric\n",
    "    y_train =  y_train.argmax(axis=1)\n",
    "        \n",
    "    # Convert dimensions\n",
    "    x_train, y_train = change_array_dimension(x_train, y_train, len(y_train))\n",
    "    x_test, y_test = change_array_dimension(x_test, [], x_test.shape[0])\n",
    "    \n",
    "    #Save data\n",
    "    np.save('./input/preprocess/changing-image-dimensions-to-3x32x32/x_train.npy', x_train)\n",
    "    np.save('./input/preprocess/changing-image-dimensions-to-3x32x32/x_test.npy', x_test)\n",
    "    np.save('./input/preprocess/changing-image-dimensions-to-3x32x32/y_train.npy', y_train)\n",
    "else:\n",
    "    # The data, split between train and test sets:\n",
    "    x_train = np.load('./input/preprocess/changing-image-dimensions-to-3x32x32/x_train.npy')\n",
    "    x_test = np.load('./input/preprocess/changing-image-dimensions-to-3x32x32/x_test.npy')\n",
    "    y_train = np.load('./input/preprocess/changing-image-dimensions-to-3x32x32/y_train.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('./input/train.csv')\n",
    "y_train = df_data['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196299 train samples\n",
      "153730 test samples\n",
      "Class spread:  Counter({0: 131457, 19: 14106, 13: 8623, 11: 7209, 8: 6938, 1: 6102, 16: 5975, 17: 4759, 3: 3398, 18: 3035, 4: 2210, 14: 1361, 10: 1093, 22: 33})\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(\"Class spread: \", collections.Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = 3000\n",
    "all_indices = []\n",
    "for class_id, class_count in collections.Counter(y_train).most_common():\n",
    "    # Take the indices of current class\n",
    "    indices = np.argwhere(y_train == class_id).squeeze()\n",
    "    \n",
    "    # Up- or down-sample the current class\n",
    "    if class_count >= max_count: # Down-sample, take unique indices\n",
    "        random_indices = list(random.sample(list(indices),max_count))\n",
    "    else: #Up-sample, take unique indices + duplicate indices\n",
    "        random_indices = list(random.sample(list(indices),class_count))\n",
    "        random_indices.extend(list(np.random.choice(indices,max_count-class_count)))\n",
    "        \n",
    "    # Add the selected indices of the class to list\n",
    "    all_indices.extend(random_indices)\n",
    "\n",
    "# Shuffle the order of the images\n",
    "all_indices=np.random.permutation(all_indices)\n",
    "\n",
    "y_train_len = len(y_train)\n",
    "y_train2 = y_train[all_indices]\n",
    "x_train2 = x_train[all_indices]\n",
    "\n",
    "print(\"Reduced the amount of training samples from {} to {}\".format(y_train_len, len(y_train2)))\n",
    "print(\"Class spread: \",collections.Counter(y_train2).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176669 samples, validate on 19630 samples\n"
     ]
    }
   ],
   "source": [
    "# Split training data to two sets: use 90 % to train and 10 % to validate\n",
    "\n",
    "# Create tensors and torch dataset\n",
    "x_train_tensor = torch.FloatTensor(x_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Split the dataset\n",
    "train_size = int(0.9 * x_train.shape[0])\n",
    "validation_size = x_train.shape[0] - train_size\n",
    "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
    "print(\"Train on {} samples, validate on {} samples\".format(train_size, validation_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the Model\n",
    "\n",
    "<img src=\"darknet-architecture.JPG\" width=300 style=\"float: right;\">\n",
    "\n",
    " https://pjreddie.com/media/files/papers/YOLOv3.pdf\n",
    "\n",
    "+copied from darknet code https://github.com/cfotache/pytorch_objectdetecttrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def __init__(self, num_classes, img_size, use_leakyrelu=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        num_classes       number of classes used in Softmax\n",
    "        img_size          size of the image used in Global average pooling\n",
    "        use_leakyrelu     if True LeakyReLU is used instead of ReLU\n",
    "        \"\"\"\n",
    "        super(Darknet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        \n",
    "        #Layer 3 x1\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(negative_slope=0.1) if use_leakyrelu else nn.ReLU())\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        \n",
    "        # Layer 5 x2\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(negative_slope=0.1) if use_leakyrelu else nn.ReLU())\n",
    "    \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "\n",
    "        # Layer 7 x8\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(negative_slope=0.1) if use_leakyrelu else nn.ReLU())\n",
    "        \n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        \n",
    "        # Layer 9 x8\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(negative_slope=0.1) if use_leakyrelu else nn.ReLU())\n",
    "        \n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        \n",
    "        # Layer 11 x4\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(negative_slope=0.1) if use_leakyrelu else nn.ReLU())\n",
    "        \n",
    "        self.layer12 = nn.AvgPool2d(kernel_size=img_size)\n",
    "        #self.layer13 = nn.Linear(img_size, num_classes)\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Linear(img_size, 1000),\n",
    "            nn.Linear(1000, num_classes))\n",
    "        self.layer14 = nn.LogSoftmax(dim=0)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        for i in range(0,2): x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        for i in range(0,8): x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        for i in range(0,8): x = self.layer9(x)\n",
    "        x = self.layer10(x)\n",
    "        for i in range(0,4): x = self.layer11(x)\n",
    "        x=x.view(x.shape[0],32,32,1)\n",
    "        x = self.layer12(x).squeeze()\n",
    "        x = self.layer13(x)\n",
    "        x = self.layer14(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  14\n"
     ]
    }
   ],
   "source": [
    "img_size=32\n",
    "classes = ['empty', 'deer', 'moose', 'squirrel', 'rodent', 'small_mammal', \n",
    "           'elk', 'pronghorn_antelope', 'rabbit', 'bighorn_sheep', 'fox', \n",
    "           'coyote', 'black_bear', 'raccoon', 'skunk', 'wolf', 'bobcat', \n",
    "           'cat', 'dog', 'opossum', 'bison', 'mountain_goat', 'mountain_lion']\n",
    "num_classes = num_classes = len(pd.Series(y_train).unique()) # Note that the training samples only cover classes form 0 to 13\n",
    "print(\"Number of classes: \", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Darknet(num_classes,img_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = False\n",
    "\n",
    "#Create dataloaders for training and validation\n",
    "batch_size = 16#64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, testloader):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    model              model used for predicting\n",
    "    testloader         batched dataset for predicting\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            real_values.extend(y.cpu().numpy())\n",
    "\n",
    "    return np.array(predictions), np.array(real_values)\n",
    "\n",
    "def get_accuracy_score(model, testloader):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    model              model used for predicting\n",
    "    testloader         batched dataset for predicting and validating\n",
    "    \"\"\"\n",
    "    predictions, real_values = get_predictions(model, testloader)\n",
    "    return accuracy_score(predictions,real_values)\n",
    "\n",
    "def train_model(model,dataloader,testloader,n_epochs,use_SGD_optimizer=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    model              model used for training\n",
    "    dataloader         batched dataset for training\n",
    "    testloader         batched dataset for validating\n",
    "    n_epochs           number of epochs used in training\n",
    "    use_SGD_optimizer  if True, SGD optimizer is used for training. Otherwise Adam.\n",
    "    verbose            if True, statistics are printed\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) if use_SGD_optimizer \\\n",
    "                    else optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (x, y) in enumerate(dataloader, 0):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # zero the parameter gradients         \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # get statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # print statistics per epoch\n",
    "        if verbose:\n",
    "            training_accuracy = get_accuracy_score(model,dataloader)\n",
    "            validation_accuracy = get_accuracy_score(model,testloader)\n",
    "            print(\"[{}] loss: {:.3f}, training accuracy: {:.3f}, validation accuracy: {:.3f}\".format(\n",
    "                        epoch+1, running_loss/len(dataloader), training_accuracy, validation_accuracy))\n",
    "            torch.save(model.state_dict(), 'darknet_linear1000_{}_epochs.pth'.format(epoch+1))\n",
    "            \n",
    "    if verbose: print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    # Create the model\n",
    "    model = Darknet(num_classes,img_size)\n",
    "    model.to(device)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 30\n",
    "    train_model(model,train_dataloader,validation_dataloader,num_epochs) \n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'darknet.pth')\n",
    "    #torch.save(model.state_dict(), 'darknet.pth')\n",
    "else:\n",
    "    # Load the model\n",
    "    model = Darknet(num_classes,img_size)\n",
    "    model.load_state_dict(torch.load('.\\prediction-models\\darknet_16_sub5.pth', map_location=lambda storage, loc: storage))\n",
    "    model.to(device)\n",
    "    #model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions, training_real_values = get_predictions(model,train_dataloader)\n",
    "validation_predictions, validation_real_values = get_predictions(model,validation_dataloader)\n",
    "print(\"Training accuracy: {}, Validation accuracy: {}\".format(accuracy_score(training_predictions,training_real_values),\n",
    "                                                             accuracy_score(validation_predictions,validation_real_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test, y_pred, classifier_name='Darknet-53', classes=[]):\n",
    "    c_matrix = confusion_matrix(y_test, y_pred, labels=classes) \n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.set_title(\"{} confusion matrix\".format(classifier_name))\n",
    "    sns.heatmap(c_matrix, cmap='Blues', annot=True, fmt='g', cbar=False)\n",
    "    ax.set_xlabel('Predictions')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    plt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    #plt.savefig('{}.jpg'.format(classifier_name.replace(' ','')))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for training images\")\n",
    "create_confusion_matrix(training_real_values,training_predictions,classes=range(0,num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for validation images\")\n",
    "create_confusion_matrix(validation_real_values,validation_predictions,classes=range(0,num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predicting labels for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153730, 2)\n"
     ]
    }
   ],
   "source": [
    "num_images = x_test.shape[0]\n",
    "x_test_tensor = torch.FloatTensor(x_test)\n",
    "y_test_tensor_dummy = torch.LongTensor(np.zeros(num_images))\n",
    "dataset = TensorDataset(x_test_tensor, y_test_tensor_dummy)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "predictions, real_values = get_predictions(model, dataloader)\n",
    "\n",
    "submission_df = pd.read_csv('./input/iwildcam-2019-fgvc6/sample_submission.csv')\n",
    "submission_df['Predicted'] = predictions\n",
    "print(submission_df.shape)\n",
    "submission_df.head()\n",
    "\n",
    "submission_df.to_csv('darknet_submission5.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
